server.port=7080

#Context Path
#server.context-path=/SpringBootDemo

#session超时时间
server.session-timeout=300

#是否启用debug模式
#debug=true

logging.level.org.springframework.web=DEBUG
#logging.file=D:/runtime/test.log



spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://0.0.0.0:3306/test?autoReconnect=true&useUnicode=true&characterEncoding=utf-8&failOverReadOnly=false&useSSL=true&useLegacyDatetimeCode=false&serverTimezone=Asia/Shanghai
spring.datasource.username=1
spring.datasource.password=1111

spring.banner.image.location=static/banner.png

#mybatis
mybatis.typeAliasesPackage=cn.zifangsky.mapper
mybatis.mapper-locations=classpath:cn/zifangsky/mapper/xml/*.xml

#kafka配置
kafka.producer.bootstrapServers=127.0.0.1:9092
kafka.producer.retries=3
#16K
kafka.producer.batchSize=16384
kafka.producer.lingerMs=1
#32M
kafka.producer.bufferMemory=33554432

kafka.consumer.bootstrapServers=127.0.0.1:9092
kafka.consumer.groupId=0
kafka.consumer.enableAutoCommit=false
kafka.consumer.autoCommitIntervalMs=1000
kafka.consumer.sessionTimeoutMs=30000
kafka.consumer.maxPollRecords=100
#earliest,latest
kafka.consumer.autoOffsetReset=earliest
#topic名称
mq.topicName.checkIP=topic-proxyIp
mq.topicName.weather=topic-weather


#定时任务执行频率
第4,9,13,19小时的10分5秒执行天气更新
task.updateWeather.schedule=5 10 4,9,13,19 * * ?
#每隔4分钟的第1秒检查数据库中的获取到的代理IP是否可用
task.checkProxyIp.schedule=1 4 * * * ?
#每隔9分钟的第20秒调用一个爬虫获取可用的代理IP
task.crawlProxyIp_1.schedule=20 9 * * * ?
#每隔19分钟的第40秒调用另一个爬虫获取可用的代理IP
task.crawlProxyIp_2.schedule=40 19 * * * ?


task.crawlProxyIp_3.schedule=0 31 9,10,11,12,13,14,15,16 * * ?/

task.crawlProxyIp_4.schedule=0 31 9,10,11,12,13,14,15,16 * * ?/

task.crawlProxyIp_6.schedule=0 40 9,10,11,12,13,14,15,16 * * ?/

task.crawlProxyIp_5.schedule=00 33 09 * * ?
tushare.token=67b58c0deed2c8ffaf0c34429f776367112b6b22b3f695aada9148a5







